{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "012ce352-8408-4ee7-a137-b777c4b7070c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#\n",
    "# source = inspect.getsource(train)\n",
    "# parsed = ast.parse(source)\n",
    "\n",
    "# for node in ast.walk(parsed):\n",
    "#     if isinstance(node,ast.Call):\n",
    "#         if isinstance(node.func, ast.Attribute):\n",
    "#             if (node.func.value.id == 'layer'):\n",
    "#                     if(node.func.attr == 'get_dataset'):\n",
    "#                         print(ast.dump(node))\n",
    "#                         print(node.args[0].value)\n",
    "\n",
    "\n",
    "# ast.dump(parsed)\n",
    "\n",
    "import pandas as pd\n",
    "import inspect\n",
    "import os\n",
    "import sys\n",
    "import inspect\n",
    "import ast\n",
    "\n",
    "\n",
    "class Layer:\n",
    "    entities = []\n",
    "    entity_context = None\n",
    "\n",
    "    def __init__(self, project_name, environment):\n",
    "        self.project_name = project_name\n",
    "        self.environment = environment\n",
    "\n",
    "    def setup(self):\n",
    "        if os.path.exists(self.environment):\n",
    "            file1 = open(self.environment, 'r')\n",
    "            for lib in file1.readlines():\n",
    "                print(f\"Layer Infra: Installing {lib.strip()}...\")\n",
    "        else:\n",
    "            print(f\"Environment file not found: {self.environment}\")\n",
    "\n",
    "    def log_parameter(self, metric, value):\n",
    "        print(f\"\\t{Layer.entity_context} > Parameter > {metric}:{value}\")\n",
    "\n",
    "    def log_metric(self, metric, value):\n",
    "        print(f\"\\t{Layer.entity_context} > Metric >{metric}:{value}\")\n",
    "\n",
    "    def log(self, message):\n",
    "        print(f\"\\t{Layer.entity_context} > {message}\")\n",
    "\n",
    "    def run(self, entities):\n",
    "        self.entities = []\n",
    "        for entity in entities:\n",
    "            if entity._type == \"dataset\":\n",
    "                self.entities.append(Dataset(entity))\n",
    "            elif entity._type == \"model\":\n",
    "                self.entities.append(Model(entity))\n",
    "\n",
    "        print(f\"--- Layer Infra: Running Project: {self.project_name} ---\")\n",
    "\n",
    "        self.setup()\n",
    "\n",
    "        for entity in self.entities:\n",
    "            entity.run()\n",
    "        print(f\"\\n--- Layer Infra: Run Complete! ---\")\n",
    "\n",
    "    def get_dataset(self, name):\n",
    "        for entity in self.entities:\n",
    "            if entity.name == name:\n",
    "                return entity\n",
    "        raise Exception(f\"Entity '{name}' not found!\")\n",
    "\n",
    "\n",
    "class Model:\n",
    "    result = None\n",
    "\n",
    "    def __init__(self, func):\n",
    "        if func:\n",
    "            self.name = func._name\n",
    "            self.func = func\n",
    "\n",
    "    def run(self):\n",
    "        self.result = self.func()\n",
    "\n",
    "\n",
    "class Dataset:\n",
    "    result = None\n",
    "\n",
    "    def __init__(self, func):\n",
    "        if func:\n",
    "            self.name = func._name\n",
    "            self.func = func\n",
    "\n",
    "    def run(self):\n",
    "        self.result = self.func()\n",
    "\n",
    "    def to_pandas(self):\n",
    "        return self.result\n",
    "\n",
    "\n",
    "def dataset(name):\n",
    "    def inner(func):\n",
    "        func._type = \"dataset\"\n",
    "        func._name = name\n",
    "\n",
    "        def wrapped(*args):\n",
    "            Layer.entity_context = func._name\n",
    "            print(f'\\nBuilding {Layer.entity_context}...')\n",
    "            res = func()\n",
    "            # TODO save returning entity to catalog\n",
    "            return res\n",
    "        wrapped._type = \"dataset\"\n",
    "        wrapped._name = name\n",
    "\n",
    "        return wrapped\n",
    "\n",
    "    return inner\n",
    "\n",
    "\n",
    "def model(name):\n",
    "    def inner(func):\n",
    "        def wrapped(*args):\n",
    "            Layer.entity_context = name\n",
    "            print(f'\\nTraining {Layer.entity_context}...')\n",
    "            res = func()\n",
    "            # TODO save returning entity to catalog\n",
    "            return res\n",
    "        wrapped._type = \"model\"\n",
    "        wrapped._name = name\n",
    "\n",
    "        return wrapped\n",
    "\n",
    "    return inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6e84fd18-1742-4c12-b6ee-63774270d01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Layer Infra: Running Project: credit-score ---\n",
      "Layer Infra: Installing scikit-learn==1.0.1...\n",
      "\n",
      "Building previous_application...\n",
      "\tprevious_application > Total previous_application: 45187\n",
      "\n",
      "Building application_features...\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Entity 'application_dataset' not found!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/n2/q9x70wpj51vfc4vh2g0h253w0000gn/T/ipykernel_89046/254649497.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"credit-score\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menvironment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'requirements.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;31m# ++ To run the whole project on Layer Infra\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mread_application_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextract_application_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;31m# ++ To train model on Layer infra\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/n2/q9x70wpj51vfc4vh2g0h253w0000gn/T/ipykernel_89046/2536276137.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, entities)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mentity\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0mentity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n--- Layer Infra: Run Complete! ---\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/n2/q9x70wpj51vfc4vh2g0h253w0000gn/T/ipykernel_89046/2536276137.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mto_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/n2/q9x70wpj51vfc4vh2g0h253w0000gn/T/ipykernel_89046/2536276137.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mLayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentity_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'\\nBuilding {Layer.entity_context}...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m             \u001b[0;31m# TODO save returning entity to catalog\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/n2/q9x70wpj51vfc4vh2g0h253w0000gn/T/ipykernel_89046/254649497.py\u001b[0m in \u001b[0;36mextract_application_features\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'application_features'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mextract_application_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"application_dataset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# credit amount ratio relative to the income of a client\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/n2/q9x70wpj51vfc4vh2g0h253w0000gn/T/ipykernel_89046/2536276137.py\u001b[0m in \u001b[0;36mget_dataset\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mentity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mentity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Entity '{name}' not found!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Entity 'application_dataset' not found!"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "import pandas as pd\n",
    "\n",
    "@dataset(\"application_dataset\")\n",
    "def read_application_data():\n",
    "    df = pd.read_csv(\"application_train.csv\")\n",
    "    layer.log(f\"Total applications: {len(df)}\")\n",
    "    return df\n",
    "\n",
    "@dataset(\"installments_payments\")\n",
    "def read_installments_data():\n",
    "    df = pd.read_csv(\"installments_payments.csv\")\n",
    "    layer.log(f\"Total installments_payments: {len(df)}\")\n",
    "    return df\n",
    "\n",
    "@dataset(\"previous_application\")\n",
    "def read_application_data():\n",
    "    df = pd.read_csv(\"previous_application.csv\")\n",
    "    layer.log(f\"Total previous_application: {len(df)}\")\n",
    "    return df\n",
    "\n",
    "@dataset(\"application_features\")\n",
    "def extract_application_features():\n",
    "    df = layer.get_dataset(\"application_dataset\").to_pandas()\n",
    "\n",
    "    # credit amount ratio relative to the income of a client\n",
    "    df['CREDIT_INCOME_RATIO'] = df['AMT_CREDIT'] / df['AMT_INCOME_TOTAL']\n",
    "\n",
    "    # loan annuity percentage relative to the income of a client\n",
    "    df['ANNUITY_INCOME_RATIO'] = df['AMT_ANNUITY'] / df['AMT_INCOME_TOTAL']\n",
    "    # the length of the payment in months \n",
    "    df['CREDIT_TERM'] = df['AMT_ANNUITY'] / df['AMT_CREDIT']\n",
    "    # days employed relative to the age of the client\n",
    "    df['DAYS_EMPLOYED_RATIO'] = df['DAYS_EMPLOYED'] / df['DAYS_BIRTH']\n",
    "    layer.log(f'Features: {list(df.columns)}')\n",
    "    layer.log(f'Total Count: {len(df)}')\n",
    "    return df\n",
    "\n",
    "\n",
    "@model(name=\"credit-score-model\")\n",
    "def train():\n",
    "    application_features = layer.get_dataset(\"application_features\").to_pandas()\n",
    "    previous_application_features = layer.get_dataset(\"previous_application\").to_pandas()\n",
    "    installments_payments = layer.get_dataset(\"installments_payments\").to_pandas()\n",
    "    dff = installments_payments.merge(previous_application_features, on=['SK_ID_PREV', 'SK_ID_CURR']).\\\n",
    "           merge(application_features,on=['SK_ID_CURR'])\n",
    "    \n",
    "    layer.log(f\"Training data count: {len(dff)}\")\n",
    "\n",
    "    X = dff.drop([\"TARGET\", \"SK_ID_CURR\",'index'], axis=1)\n",
    "    y = dff[\"TARGET\"]\n",
    "    random_state = 13\n",
    "    test_size = 0.3\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size,\n",
    "                                                        random_state=random_state)\n",
    "    categories = dff.select_dtypes(include=['object']).columns.tolist() \n",
    "\n",
    "    transformer = ColumnTransformer(transformers=[('cat', OneHotEncoder(handle_unknown='ignore', drop=\"first\"), categories)],remainder='passthrough')\n",
    "     # Model Parameters\n",
    "    learning_rate = 0.01\n",
    "    max_depth = 6\n",
    "    min_samples_leaf = 10\n",
    "    random_state = 42\n",
    "    early_stopping = True\n",
    "    # Model: Define a HistGradient Boosting Classifier\n",
    "    model = HistGradientBoostingClassifier(learning_rate=learning_rate,\n",
    "                               max_depth=max_depth,\n",
    "                               min_samples_leaf=min_samples_leaf,\n",
    "                                early_stopping=early_stopping,\n",
    "                               random_state=random_state)\n",
    "\n",
    "     # Pipeline fit\n",
    "    pipeline = Pipeline(steps=[('transformer', transformer), ('model', model)])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "                     # Predict probabilities of target\n",
    "    probs = pipeline.predict_proba(X_test)[:,1]\n",
    "    # Calculate average precision and area under the receiver operating characteric curve (ROC AUC)\n",
    "    avg_precision = average_precision_score(y_test, probs, pos_label=1)\n",
    "    auc = roc_auc_score(y_test, probs)\n",
    "    layer.log_metric(\"AUC\", f'{auc:.4f}')\n",
    "    layer.log_metric(\"avg_precision\", f'{avg_precision:.4f}')\n",
    "\n",
    "    \n",
    "    return pipeline\n",
    "\n",
    "\n",
    "# ++ init Layer\n",
    "layer = Layer(project_name=\"credit-score\", environment='requirements.txt')\n",
    "# ++ To run the whole project on Layer Infra\n",
    "layer.run([read_application_data,read_installments_data, extract_application_features, train])\n",
    "\n",
    "# ++ To train model on Layer infra\n",
    "# layer.run([train])\n",
    "\n",
    "# ++ To debug the code locally, just call the function:\n",
    "# train()\n",
    "# extract_features()\n",
    "\n",
    "# read_and_clean_dataset()\n",
    "# train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80806d54-725d-460c-8dc4-b81085b083c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
